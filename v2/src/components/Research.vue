<template>
  <div class="research mt-10 px-10">
    <h1>Research</h1>
    <a class="hover:underline text-sky-500" href="https://scholar.google.com/citations?user=J8FuRZgAAAAJ&hl=ja">https://scholar.google.com/citations?user=J8FuRZgAAAAJ&hl=ja</a>
    <div class="bg-white rounded-md mt-1 pl-10 pr-6 py-4 shadow-md">
      <ul class="list-square">
        <li>Koki Wataoka, Tsubasa Takahashi, Ryokan Ri, "Self-Preference Bias in LLM-as-a-Judge", NeurIPS 2024 Safety Generative AI Workshop</li>
        <li>Thien Q Tran, Koki Wataoka, Tsubasa Takahashi, "Initial Response Selection for Prompt Jailbreaking using Model Steering", ICLR 2024 Secure and Trustworthy Large Language Models Workshop</li>
        <li>Keita Saito, Akifumi Wachi, Koki Wataoka, Youhei Akimoto, "Verbosity bias in preference labeling by large language models", NeurIPS 2023 Instruction Tuning and Instruction Following Workshop</li>
        <li>綿岡晃輝, 野崎 雄斗, 馬越 雅人, 高橋 翼, "言語モデルの倫理的検査のための効率的なテストケースの生成", Computer Security Symposium (CSS), 2022. <b class="text-red-500">CSS奨励賞</b></li>
        <li>Koki Wataoka, Takashi Matsubara, Kuniaki Uehara, “Counterfactual Image Generation using GAN for Fairness,” 情報処理学会 コンピュータビジョンとイメージメディア研究会(CVIM), vol. 2021-CVIM-225, no. 4, オンライン, 3月, 2021.</li>
        <li>綿岡晃輝, 松原崇, 上原邦昭, “公平性により生じる敵対的攻撃に対する脆弱性,” 2020年度 第34回人工知能学会全国大会(JSAI2020), 熊本, 6月, 2020.</li>
        <li>綿岡晃輝, 松原崇, 上原邦昭, “公平性が引き起こす敵対的攻撃に対する脆弱性,” 電子情報通信学会 情報論的学習理論と機械学習研究会, vol. 119, no. 476, IBISML2019-48, pp .101-105, 京都, 3月, 2020.</li>
        <li>綿岡晃輝, 松原崇, 上原邦昭, “敵対的攻撃に対する公平な分類器の脆弱性,” 電子情報通信学会総合大会講演論文集, D-12-7, 広島, 3月, 2020.</li>
      </ul>
    </div>
  </div>
</template>

<script>
export default {
  name: "Career",
};
</script>

<!-- Add "scoped" attribute to limit CSS to this component only -->
<style scoped></style>
